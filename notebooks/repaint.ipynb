{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Media burned in – saved to screen_with_media.mp4\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- centre-aligned, over-scaled media replacement ----------------\n",
    "import cv2, json, numpy as np, logging, math, pathlib\n",
    "\n",
    "# ── files ──────────────────────────────────────────────────────────────\n",
    "TRACK_JSON = \"aruco_screen_tracks.json\"   # produced by the tracker\n",
    "VIDEO_IN   = \"aruco.mp4\"                  # original recording\n",
    "MEDIA_IMG  = \"media.png\"                  # picture to show on screen\n",
    "VIDEO_OUT  = \"screen_with_media.mp4\"      # result\n",
    "ALPHA      = 0.0                          # 0 = full replace; >0 = faint underlay\n",
    "\n",
    "# ── debug log (optional) ───────────────────────────────────────────────\n",
    "logging.basicConfig(filename=\"replace_debug.log\",\n",
    "                    filemode=\"w\", level=logging.DEBUG, format=\"%(message)s\")\n",
    "log = logging.getLogger(\"replace\")\n",
    "\n",
    "# ═══ 1.  load tracking JSON ════════════════════════════════════════════\n",
    "with open(TRACK_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "frames = meta[\"frames\"]\n",
    "FW, FH = meta[\"frame_width\"], meta[\"frame_height\"]\n",
    "\n",
    "# ═══ 2.  open video & media image ═════════════════════════════════════\n",
    "cap  = cv2.VideoCapture(VIDEO_IN)\n",
    "fps  = cap.get(cv2.CAP_PROP_FPS)\n",
    "four = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out  = cv2.VideoWriter(VIDEO_OUT, four, fps, (FW, FH))\n",
    "\n",
    "media = cv2.imread(MEDIA_IMG)\n",
    "if media is None:\n",
    "    raise RuntimeError(f\"Cannot read {MEDIA_IMG}\")\n",
    "mh, mw = media.shape[:2]\n",
    "\n",
    "# reusable 4-point source quad\n",
    "src_quad = np.zeros((4, 2), np.float32)\n",
    "\n",
    "# ═══ 3.  frame loop ═══════════════════════════════════════════════════\n",
    "for rec in frames:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    if not rec[\"valid\"]:\n",
    "        out.write(frame)\n",
    "        continue\n",
    "\n",
    "    dst_quad = np.array(rec[\"corners\"], np.float32)   # TL,TR,BR,BL\n",
    "\n",
    "    # overlay size this frame\n",
    "    ov_w = int(np.linalg.norm(dst_quad[1] - dst_quad[0]) + 0.5)   # top edge\n",
    "    ov_h = int(np.linalg.norm(dst_quad[3] - dst_quad[0]) + 0.5)   # left edge\n",
    "\n",
    "    # -------- always overscale *at least* one pixel larger -----------\n",
    "    scale = max(ov_w / mw, ov_h / mh) * 1.01        # +1 % safety\n",
    "    big   = cv2.resize(media,\n",
    "                       (math.ceil(mw * scale), math.ceil(mh * scale)),\n",
    "                       interpolation=cv2.INTER_AREA)\n",
    "    bh, bw = big.shape[:2]\n",
    "\n",
    "    # centred crop to exact overlay size (keeps centre of mass)\n",
    "    x0 = max(0, (bw - ov_w) // 2)\n",
    "    y0 = max(0, (bh - ov_h) // 2)\n",
    "    patch = big[y0:y0 + ov_h, x0:x0 + ov_w]\n",
    "\n",
    "    # source quad matches patch\n",
    "    ph, pw = patch.shape[:2]        # pw==ov_w , ph==ov_h\n",
    "    src_quad[:] = [[0, 0], [pw - 1, 0], [pw - 1, ph - 1], [0, ph - 1]]\n",
    "\n",
    "    # -------- warp & composite ---------------------------------------\n",
    "    H      = cv2.getPerspectiveTransform(src_quad, dst_quad)\n",
    "    warped = cv2.warpPerspective(patch, H, (FW, FH))\n",
    "\n",
    "    mask   = cv2.warpPerspective(np.full((ph, pw), 255, np.uint8), H, (FW, FH))\n",
    "    mask_i = cv2.bitwise_not(mask)\n",
    "\n",
    "    if ALPHA:\n",
    "        base = cv2.addWeighted(frame, 1 - ALPHA, warped, ALPHA, 0)\n",
    "        frame = cv2.bitwise_and(base, base, mask=mask) + cv2.bitwise_and(frame, frame, mask=mask_i)\n",
    "    else:\n",
    "        frame = cv2.bitwise_and(frame, frame, mask=mask_i) + cv2.bitwise_and(warped, warped, mask=mask)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release(); out.release()\n",
    "print(\"✅  Media burned in – saved to\", VIDEO_OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
