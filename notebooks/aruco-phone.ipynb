{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aruco is available.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "if hasattr(cv2, \"aruco\"):\n",
    "    print(\"Aruco is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Finished – written to aruco_green_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "# Cell: find-QR-then-overlay\n",
    "import cv2, json, numpy as np, logging, math, os\n",
    "\n",
    "# ── files ───────────────────────────────────────────────────────────\n",
    "VIDEO_IN  = \"aruco.mp4\"                 # input clip\n",
    "VIDEO_OUT = \"aruco_green_overlay.mp4\"   # output with overlay\n",
    "\n",
    "# ── logging ─────────────────────────────────────────────────────────\n",
    "logging.basicConfig(filename=\"aruco_debug.log\",\n",
    "                    filemode=\"w\",\n",
    "                    level=logging.DEBUG,\n",
    "                    format=\"%(message)s\")\n",
    "log = logging.getLogger(\"aruco\")\n",
    "\n",
    "# ═════════ 1st pass : hunt for the QR with metadata ═════════════════\n",
    "cap = cv2.VideoCapture(VIDEO_IN)\n",
    "qr   = cv2.QRCodeDetector()\n",
    "\n",
    "meta = None\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:                                      # end-of-video\n",
    "        break\n",
    "    payload, *_ = qr.detectAndDecode(frame)\n",
    "    if payload:\n",
    "        try:\n",
    "            meta = json.loads(payload)\n",
    "        except json.JSONDecodeError:\n",
    "            raise RuntimeError(\"QR decoded but payload is not valid JSON\")\n",
    "        break                                       # stop at first good QR\n",
    "\n",
    "if meta is None:\n",
    "    raise RuntimeError(\"No metadata QR code found in the entire video\")\n",
    "\n",
    "# ── verify mandatory keys in the JSON ───────────────────────────────\n",
    "need = {\"dictionary\", \"marker_size_px\", \"margin_px\",\n",
    "        \"corner_markers\", \"screen_aspect\"}\n",
    "missing = need - meta.keys()\n",
    "if missing:\n",
    "    raise RuntimeError(f\"QR metadata missing keys: {missing}\")\n",
    "\n",
    "# ═════════ constants derived ONLY from the QR ═══════════════════════\n",
    "aruco_dict_name = meta[\"dictionary\"]\n",
    "dictionary      = cv2.aruco.getPredefinedDictionary(\n",
    "                      getattr(cv2.aruco, aruco_dict_name))\n",
    "margin_px  = int(meta[\"margin_px\"])\n",
    "BASE_RATIO = float(meta[\"screen_aspect\"])\n",
    "\n",
    "# corner mapping  — ID → (internal-corner-idx, (dx,dy shift))\n",
    "sign = {\"TL\":(-1,-1), \"TR\":(1,-1), \"BR\":(1,1), \"BL\":(-1,1)}\n",
    "corner_map = {}\n",
    "for lbl in (\"TL\",\"TR\",\"BR\",\"BL\"):\n",
    "    info = meta[\"corner_markers\"][lbl]\n",
    "    corner_map[info[\"id\"]] = (info[\"corner_index\"],\n",
    "                              (sign[lbl][0]*margin_px,\n",
    "                               sign[lbl][1]*margin_px))\n",
    "\n",
    "# heuristics scale with marker size\n",
    "marker_sz  = int(meta[\"marker_size_px\"])\n",
    "JUMP_PX    = max(marker_sz//2, 20)\n",
    "OUTLIER_PX = max(marker_sz//3, 10)\n",
    "MAX_STEP_PX= max(marker_sz//10, 4)\n",
    "RATIO_TOL  = 0.10                         # keep ±10 %\n",
    "\n",
    "# ═════════ 2nd pass : full tracking & drawing ═══════════════════════\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "w   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "N   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)       # rewind\n",
    "\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, cv2.aruco.DetectorParameters())\n",
    "\n",
    "def shift(pt, dx, dy):\n",
    "    return np.array([pt[0]+dx, pt[1]+dy], np.float32)\n",
    "\n",
    "tracks    = np.full((N,4,2), np.nan, np.float32)\n",
    "last_good = [None]*4\n",
    "\n",
    "# ── pass 2a : collect / clean measurements ──────────────────────────\n",
    "for f in range(N):\n",
    "    ok, frm = cap.read()\n",
    "    if not ok: break\n",
    "    corners, ids, _ = detector.detectMarkers(frm)\n",
    "    if ids is None: continue\n",
    "    for idx, mid in enumerate(ids.flatten()):\n",
    "        if mid not in corner_map: continue\n",
    "        c,(dx,dy) = corner_map[mid]\n",
    "        raw = shift(corners[idx][0][c], dx, dy)\n",
    "        if last_good[c] is not None and np.linalg.norm(raw-last_good[c]) > JUMP_PX:\n",
    "            continue                              # spike → ignore\n",
    "        tracks[f,c] = raw\n",
    "        last_good[c] = raw\n",
    "\n",
    "# kill single-frame spikes, then linear-interpolate gaps\n",
    "for k in range(4):\n",
    "    seq = tracks[:,k,:]\n",
    "    for f in range(1,N-1):\n",
    "        if np.isnan(seq[f]).any() or np.isnan(seq[f-1]).any() or np.isnan(seq[f+1]).any():\n",
    "            continue\n",
    "        if np.linalg.norm(seq[f]-(seq[f-1]+seq[f+1])/2) > OUTLIER_PX:\n",
    "            seq[f] = np.nan\n",
    "    tracks[:,k] = seq\n",
    "    for d in range(2):\n",
    "        s, m = tracks[:,k,d], ~np.isnan(tracks[:,k,d])\n",
    "        if m.any():\n",
    "            tracks[:,k,d] = np.interp(np.arange(N), np.where(m)[0], s[m])\n",
    "\n",
    "# ── pass 2b : draw overlay with snap-back & clamp ───────────────────\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out    = cv2.VideoWriter(VIDEO_OUT, fourcc, fps, (w,h))\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)       # rewind again\n",
    "prev_draw = None\n",
    "ALPHA = 0.30\n",
    "\n",
    "for f in range(N):\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    quad = tracks[f].copy()\n",
    "\n",
    "    # aspect-ratio snap using TL = TR + BL – BR\n",
    "    w_now = (np.linalg.norm(quad[1]-quad[0])+np.linalg.norm(quad[2]-quad[3]))*0.5\n",
    "    h_now = (np.linalg.norm(quad[3]-quad[0])+np.linalg.norm(quad[2]-quad[1]))*0.5\n",
    "    if h_now>0 and abs(w_now/h_now - BASE_RATIO) > BASE_RATIO*RATIO_TOL:\n",
    "        alt_tl = quad[1] + quad[3] - quad[2]\n",
    "        w_alt  = (np.linalg.norm(quad[1]-alt_tl)+np.linalg.norm(quad[2]-quad[3]))*0.5\n",
    "        h_alt  = (np.linalg.norm(quad[3]-alt_tl)+np.linalg.norm(quad[2]-quad[1]))*0.5\n",
    "        if h_alt>0 and abs(w_alt/h_alt - BASE_RATIO) < abs(w_now/h_now - BASE_RATIO):\n",
    "            quad[0] = alt_tl\n",
    "\n",
    "    # gentle per-frame clamp\n",
    "    if prev_draw is not None:\n",
    "        for i in range(4):\n",
    "            move = quad[i]-prev_draw[i]\n",
    "            d = np.linalg.norm(move)\n",
    "            if d > MAX_STEP_PX:\n",
    "                quad[i] = prev_draw[i] + move/d*MAX_STEP_PX\n",
    "    prev_draw = quad\n",
    "\n",
    "    # draw\n",
    "    overlay = frame.copy()\n",
    "    cv2.fillPoly(overlay, [quad.astype(np.int32)], (0,255,0))\n",
    "    frame = cv2.addWeighted(frame, 1-ALPHA, overlay, ALPHA, 0)\n",
    "    cv2.polylines(frame, [quad.astype(np.int32)], True, (0,255,0), 2)\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release(); out.release()\n",
    "print(\"✅  Finished – written to\", VIDEO_OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
