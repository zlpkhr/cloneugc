{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aruco is available.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "if hasattr(cv2, \"aruco\"):\n",
    "    print(\"Aruco is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Finished – overlay written to aruco_green_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "# %%  ----------------------  QR-DRIVEN ArUco overlay  ----------------------\n",
    "import cv2, json, numpy as np, logging, math, os, sys\n",
    "\n",
    "VIDEO_IN = \"aruco.mp4\"\n",
    "VIDEO_OUT = \"aruco_green_overlay.mp4\"\n",
    "\n",
    "# ── logging ────────────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    filename=\"aruco_debug.log\", filemode=\"w\", level=logging.DEBUG, format=\"%(message)s\"\n",
    ")\n",
    "log = logging.getLogger(\"aruco\")\n",
    "\n",
    "# ═════ PASS-0 : scan whole video for the metadata QR ═══════════════════════\n",
    "cap = cv2.VideoCapture(VIDEO_IN)\n",
    "qr = cv2.QRCodeDetector()\n",
    "\n",
    "meta = None\n",
    "while True:\n",
    "    ok, frm = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    payload, *_ = qr.detectAndDecode(frm)\n",
    "    if payload:\n",
    "        meta = json.loads(payload)  # raises if JSON invalid\n",
    "        break\n",
    "\n",
    "if meta is None:\n",
    "    raise RuntimeError(\"No metadata QR code found in the video\")\n",
    "\n",
    "needed = {\n",
    "    \"dictionary\",\n",
    "    \"marker_size_px\",\n",
    "    \"margin_px\",\n",
    "    \"corner_markers\",\n",
    "    \"screen_aspect\",\n",
    "}\n",
    "missing = needed - meta.keys()\n",
    "if missing:\n",
    "    raise RuntimeError(f\"QR metadata missing keys: {missing}\")\n",
    "\n",
    "# ── constants coming *only* from the QR ────────────────────────────────────\n",
    "dict_name = meta[\"dictionary\"]\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(getattr(cv2.aruco, dict_name))\n",
    "\n",
    "marker_px = int(meta[\"marker_size_px\"])\n",
    "margin_px = int(meta[\"margin_px\"])\n",
    "BASE_RATIO = float(meta[\"screen_aspect\"])\n",
    "\n",
    "corner_json = meta[\"corner_markers\"]  # TL / TR / BR / BL\n",
    "corner_map = {\n",
    "    corner_json[lbl][\"id\"]: corner_json[lbl][\"corner_index\"]\n",
    "    for lbl in (\"TL\", \"TR\", \"BR\", \"BL\")\n",
    "}\n",
    "\n",
    "# thresholds that scale with marker size\n",
    "JUMP_PX = max(marker_px // 2, 20)\n",
    "OUTLIER_PX = max(marker_px // 3, 10)\n",
    "MAX_STEP_PX = max(marker_px // 10, 4)\n",
    "RATIO_TOL = 0.10\n",
    "ALPHA = 0.30\n",
    "\n",
    "# ── helper to shift the *inner* marker corner to the real screen corner ────\n",
    "NEIGH_H = {0: 1, 1: 0, 2: 3, 3: 2}\n",
    "NEIGH_V = {0: 3, 1: 2, 2: 1, 3: 0}\n",
    "\n",
    "\n",
    "def screen_corner_from_marker(c4, inner, margin):\n",
    "    \"\"\"\n",
    "    c4    : 4×2 array of the marker's detected corners\n",
    "    inner : index (0-3) of the corner that touches the screen *inner* edge\n",
    "    margin: printed white margin (px) between marker and screen edge\n",
    "    \"\"\"\n",
    "    c = c4[inner]\n",
    "    h = c4[NEIGH_H[inner]]\n",
    "    v = c4[NEIGH_V[inner]]\n",
    "    u_h = (c - h) / np.linalg.norm(c - h)\n",
    "    u_v = (c - v) / np.linalg.norm(c - v)\n",
    "    diag = u_h + u_v\n",
    "    diag /= np.linalg.norm(diag)  # unit vector toward screen corner\n",
    "    return c + margin * diag  # shift exactly “margin” pixels\n",
    "\n",
    "\n",
    "# ═════ PASS-1 : detect & clean tracks ══════════════════════════════════════\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "N = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # rewind\n",
    "\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, cv2.aruco.DetectorParameters())\n",
    "tracks = np.full((N, 4, 2), np.nan, np.float32)\n",
    "last_good = [None] * 4  # previous accepted point per corner\n",
    "\n",
    "for f in range(N):\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    corners, ids, _ = detector.detectMarkers(frame)\n",
    "    if ids is None:\n",
    "        continue\n",
    "\n",
    "    for idx, mid in enumerate(ids.flatten()):\n",
    "        if mid not in corner_map:\n",
    "            continue\n",
    "        inner = corner_map[mid]  # 0-3 index from QR\n",
    "        sc = screen_corner_from_marker(corners[idx][0], inner, margin_px)\n",
    "\n",
    "        if (\n",
    "            last_good[inner] is not None\n",
    "            and np.linalg.norm(sc - last_good[inner]) > JUMP_PX\n",
    "        ):\n",
    "            continue  # ignore large single-frame jump\n",
    "        tracks[f, inner] = sc\n",
    "        last_good[inner] = sc\n",
    "\n",
    "# kill isolated spikes & linearly fill gaps\n",
    "for k in range(4):\n",
    "    seq = tracks[:, k, :]\n",
    "    for f in range(1, N - 1):\n",
    "        if (\n",
    "            np.isnan(seq[f]).any()\n",
    "            or np.isnan(seq[f - 1]).any()\n",
    "            or np.isnan(seq[f + 1]).any()\n",
    "        ):\n",
    "            continue\n",
    "        if np.linalg.norm(seq[f] - (seq[f - 1] + seq[f + 1]) / 2) > OUTLIER_PX:\n",
    "            seq[f] = np.nan\n",
    "    tracks[:, k] = seq\n",
    "    for d in range(2):\n",
    "        s, m = tracks[:, k, d], ~np.isnan(tracks[:, k, d])\n",
    "        if m.any():\n",
    "            tracks[:, k, d] = np.interp(np.arange(N), np.where(m)[0], s[m])\n",
    "\n",
    "# ═════ PASS-2 : stabilise & draw overlay ═══════════════════════════════════\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(VIDEO_OUT, fourcc, fps, (w, h))\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # rewind again\n",
    "prev_draw = None\n",
    "\n",
    "for f in range(N):\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    quad = tracks[f].copy()\n",
    "\n",
    "    # aspect-ratio snap-back (fix TL when needed)\n",
    "    w_now = (\n",
    "        np.linalg.norm(quad[1] - quad[0]) + np.linalg.norm(quad[2] - quad[3])\n",
    "    ) * 0.5\n",
    "    h_now = (\n",
    "        np.linalg.norm(quad[3] - quad[0]) + np.linalg.norm(quad[2] - quad[1])\n",
    "    ) * 0.5\n",
    "    if h_now > 0 and abs(w_now / h_now - BASE_RATIO) > BASE_RATIO * RATIO_TOL:\n",
    "        alt_tl = quad[1] + quad[3] - quad[2]\n",
    "        w_alt = (\n",
    "            np.linalg.norm(quad[1] - alt_tl) + np.linalg.norm(quad[2] - quad[3])\n",
    "        ) * 0.5\n",
    "        h_alt = (\n",
    "            np.linalg.norm(quad[3] - alt_tl) + np.linalg.norm(quad[2] - quad[1])\n",
    "        ) * 0.5\n",
    "        if h_alt > 0 and abs(w_alt / h_alt - BASE_RATIO) < abs(\n",
    "            w_now / h_now - BASE_RATIO\n",
    "        ):\n",
    "            quad[0] = alt_tl\n",
    "\n",
    "    # gentle per-frame clamp\n",
    "    if prev_draw is not None:\n",
    "        for i in range(4):\n",
    "            move = quad[i] - prev_draw[i]\n",
    "            d = np.linalg.norm(move)\n",
    "            if d > MAX_STEP_PX:\n",
    "                quad[i] = prev_draw[i] + move / d * MAX_STEP_PX\n",
    "    prev_draw = quad\n",
    "\n",
    "    # draw\n",
    "    mask = np.zeros_like(frame)\n",
    "    cv2.fillPoly(mask, [quad.astype(np.int32)], (0, 255, 0))\n",
    "    blended = cv2.addWeighted(frame, 1 - ALPHA, mask, ALPHA, 0)\n",
    "    cv2.polylines(blended, [quad.astype(np.int32)], True, (0, 255, 0), 2)\n",
    "    out.write(blended)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅  Finished – overlay written to\", VIDEO_OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
